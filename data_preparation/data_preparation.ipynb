{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# zipped_data_path = \"../data/raw_data/ucsd-cse-151b-class-competition.zip\"\n",
    "\n",
    "# dataframes = defaultdict(pd.DataFrame)\n",
    "# with zipfile.ZipFile(zipped_data_path, \"r\") as zip:\n",
    "#     for filename in zip.namelist():\n",
    "#         if filename.endswith(\".csv\"):\n",
    "#             with zip.open(filename) as f:\n",
    "#                 dataframes.update({ filename : pd.read_csv(io.TextIOWrapper(f)) })\n",
    "\n",
    "#                 # Lets take a look at the files\n",
    "#                 print(f\"FILE: {filename}\")\n",
    "#                 display(dataframes[filename].info())\n",
    "#                 display(dataframes[filename].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXI_METADATA = dataframes[\"metaData_taxistandsID_name_GPSlocation.csv\"]\n",
    "SAMPLE_SUBMISSION_DF = dataframes[\"sample_submission.csv\"]\n",
    "TEST_PUBLIC_DF = dataframes[\"test_public.csv\"]\n",
    "TRAIN_DF = dataframes[\"train.csv\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **train.csv**\n",
    "\n",
    "| Column Name | Description |\n",
    "| --- | --- |\n",
    "| TRIP_ID | (String) - An unique identifier for each trip |\n",
    "| CALL_TYPE | (char) - Category of the ride. It may contain one of three possible values: 'A' if this trip was dispatched from the central, 'B' if this trip was demanded directly to a taxi driver on a specific stand, 'C' otherwise (i.e. a trip demanded on a random street) |\n",
    "| ORIGIN_CALL | (integer) - An unique identifier for the phone number to call the taxi. It identifies the trip's customer if CALL_TYPE='A'. Otherwise, it assumes a NULL value |\n",
    "| ORIGIN_STAND | (integer) - An unique identifier for the taxi stand. It identifies the starting point of the trip if CALL_TYPE='B'. Otherwise, it assumes a NULL value |\n",
    "| TAXI_ID | (integer) - An unique identifier for the taxi that performed each trip |\n",
    "| TIMESTAMP | (integer) - Unix Timestamp (in seconds). It identifies the trip's start |\n",
    "| DAY_TYPE | (char) - It identifies the daytype of the trip's start. It assumes one of three possible values: 'A' if this trip started on a normal day or weekend, 'B' if this trip started on a holiday or other special day, 'C' if the trip started on a day before a type-B day |\n",
    "| MISSING_DATA | (Boolean) - It is FALSE when the GPS data stream is complete and TRUE whenever one (or more) locations are missing |\n",
    "| POLYLINE | (String) - A list of GPS coordinates (i.e. WGS84 format) mapped as a string. The beginning and the end of the string are identified with brackets (i.e. [ and ]). Each pair of coordinates is also identified by the same brackets as [LONGITUDE, LATITUDE]. The coordinates were recorded every 15 seconds during the trip. The first item represents the starting point and the last item corresponds to the destination |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.710670e+06</td>\n",
       "      <td>364770.000000</td>\n",
       "      <td>806579.000000</td>\n",
       "      <td>1.710670e+06</td>\n",
       "      <td>1.710670e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.388622e+18</td>\n",
       "      <td>24490.363018</td>\n",
       "      <td>30.272381</td>\n",
       "      <td>2.000035e+07</td>\n",
       "      <td>1.388622e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.180944e+15</td>\n",
       "      <td>19624.290043</td>\n",
       "      <td>17.747840</td>\n",
       "      <td>2.112405e+02</td>\n",
       "      <td>9.180944e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.372637e+18</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>1.372637e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.380731e+18</td>\n",
       "      <td>6593.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000017e+07</td>\n",
       "      <td>1.380731e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.388493e+18</td>\n",
       "      <td>18755.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.000034e+07</td>\n",
       "      <td>1.388493e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.396750e+18</td>\n",
       "      <td>40808.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2.000052e+07</td>\n",
       "      <td>1.396750e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.404173e+18</td>\n",
       "      <td>63884.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>2.000098e+07</td>\n",
       "      <td>1.404173e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TRIP_ID    ORIGIN_CALL   ORIGIN_STAND       TAXI_ID     TIMESTAMP\n",
       "count  1.710670e+06  364770.000000  806579.000000  1.710670e+06  1.710670e+06\n",
       "mean   1.388622e+18   24490.363018      30.272381  2.000035e+07  1.388622e+09\n",
       "std    9.180944e+15   19624.290043      17.747840  2.112405e+02  9.180944e+06\n",
       "min    1.372637e+18    2001.000000       1.000000  2.000000e+07  1.372637e+09\n",
       "25%    1.380731e+18    6593.000000      15.000000  2.000017e+07  1.380731e+09\n",
       "50%    1.388493e+18   18755.000000      27.000000  2.000034e+07  1.388493e+09\n",
       "75%    1.396750e+18   40808.000000      49.000000  2.000052e+07  1.396750e+09\n",
       "max    1.404173e+18   63884.000000      63.000000  2.000098e+07  1.404173e+09"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRIP_ID               0\n",
       "CALL_TYPE             0\n",
       "ORIGIN_CALL     1345900\n",
       "ORIGIN_STAND     904091\n",
       "TAXI_ID               0\n",
       "TIMESTAMP             0\n",
       "DAY_TYPE              0\n",
       "MISSING_DATA          0\n",
       "POLYLINE              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MISSING_DATA\n",
       "False    1710660\n",
       "True          10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many GPS data streams are complete vs incomplete\n",
    "TRAIN_DF[\"MISSING_DATA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MISSING_DATA\n",
       "False    1710660\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets remove the missing data\n",
    "TRAIN_DF = TRAIN_DF[TRAIN_DF[\"MISSING_DATA\"] != True]\n",
    "TRAIN_DF[\"MISSING_DATA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CALL_TYPE\n",
       "B    0.478107\n",
       "C    0.308660\n",
       "A    0.213233\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of each call type\n",
    "TRAIN_DF[\"CALL_TYPE\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAY_TYPE\n",
       "A    1.0\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of each day type\n",
    "TRAIN_DF[\"DAY_TYPE\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tyler Holston\\AppData\\Local\\Temp\\ipykernel_3120\\466646351.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TRAIN_DF[\"TRAVEL_TIME\"] = TRAIN_DF[\"POLYLINE\"].apply(calculate_travel_time)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000589</td>\n",
       "      <td>1372636858</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.618643,41.141412],[-8.618499,41.141376],[...</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20000596</td>\n",
       "      <td>1372637303</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.639847,41.159826],[-8.640351,41.159871],[...</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372636951620000320</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000320</td>\n",
       "      <td>1372636951</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.612964,41.140359],[-8.613378,41.14035],[-...</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372636854620000520</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>1372636854</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.574678,41.151951],[-8.574705,41.151942],[...</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000337</td>\n",
       "      <td>1372637091</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.645994,41.18049],[-8.645949,41.180517],[-...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   \n",
       "0  1372636858620000589         C          NaN           NaN  20000589  \\\n",
       "1  1372637303620000596         B          NaN           7.0  20000596   \n",
       "2  1372636951620000320         C          NaN           NaN  20000320   \n",
       "3  1372636854620000520         C          NaN           NaN  20000520   \n",
       "4  1372637091620000337         C          NaN           NaN  20000337   \n",
       "\n",
       "    TIMESTAMP DAY_TYPE  MISSING_DATA   \n",
       "0  1372636858        A         False  \\\n",
       "1  1372637303        A         False   \n",
       "2  1372636951        A         False   \n",
       "3  1372636854        A         False   \n",
       "4  1372637091        A         False   \n",
       "\n",
       "                                            POLYLINE  TRAVEL_TIME  \n",
       "0  [[-8.618643,41.141412],[-8.618499,41.141376],[...          330  \n",
       "1  [[-8.639847,41.159826],[-8.640351,41.159871],[...          270  \n",
       "2  [[-8.612964,41.140359],[-8.613378,41.14035],[-...          960  \n",
       "3  [[-8.574678,41.151951],[-8.574705,41.151942],[...          630  \n",
       "4  [[-8.645994,41.18049],[-8.645949,41.180517],[-...          420  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def calculate_travel_time(polyline: str) -> int:\n",
    "    \"\"\"\n",
    "    Calculates the travel time of a trip. Is defined as\n",
    "    (number of points - 1) * 15 seconds.\n",
    "    \n",
    "    :param polyline: The polyline of the trip.\n",
    "    :return: The travel time of the trip.\n",
    "    \"\"\"\n",
    "    return (len(json.loads(polyline)) - 1) * 15\n",
    "\n",
    "TRAIN_DF[\"TRAVEL_TIME\"] = TRAIN_DF[\"POLYLINE\"].apply(calculate_travel_time)\n",
    "TRAIN_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000589</td>\n",
       "      <td>1372636858</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.618643,41.141412],[-8.618499,41.141376],[...</td>\n",
       "      <td>330</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20000596</td>\n",
       "      <td>1372637303</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.639847,41.159826],[-8.640351,41.159871],[...</td>\n",
       "      <td>270</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372636951620000320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000320</td>\n",
       "      <td>1372636951</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.612964,41.140359],[-8.613378,41.14035],[-...</td>\n",
       "      <td>960</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372636854620000520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>1372636854</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.574678,41.151951],[-8.574705,41.151942],[...</td>\n",
       "      <td>630</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000337</td>\n",
       "      <td>1372637091</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.645994,41.18049],[-8.645949,41.180517],[-...</td>\n",
       "      <td>420</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   TIMESTAMP   \n",
       "0  1372636858620000589          NaN           NaN  20000589  1372636858  \\\n",
       "1  1372637303620000596          NaN           7.0  20000596  1372637303   \n",
       "2  1372636951620000320          NaN           NaN  20000320  1372636951   \n",
       "3  1372636854620000520          NaN           NaN  20000520  1372636854   \n",
       "4  1372637091620000337          NaN           NaN  20000337  1372637091   \n",
       "\n",
       "   MISSING_DATA                                           POLYLINE   \n",
       "0         False  [[-8.618643,41.141412],[-8.618499,41.141376],[...  \\\n",
       "1         False  [[-8.639847,41.159826],[-8.640351,41.159871],[...   \n",
       "2         False  [[-8.612964,41.140359],[-8.613378,41.14035],[-...   \n",
       "3         False  [[-8.574678,41.151951],[-8.574705,41.151942],[...   \n",
       "4         False  [[-8.645994,41.18049],[-8.645949,41.180517],[-...   \n",
       "\n",
       "   TRAVEL_TIME  CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  \n",
       "0          330        False        False         True  \n",
       "1          270        False         True        False  \n",
       "2          960        False        False         True  \n",
       "3          630        False        False         True  \n",
       "4          420        False        False         True  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets split DATA_TYPE and CALL_TYPE into three new binary features \n",
    "# i.e. if DATA_TYPE = 'A' -> DATA_TYPE_A = 1, DATA_TYPE_B = 0, DATA_TYPE_C = 0\n",
    "#day_type_dummies = pd.get_dummies(TRAIN_DF['DAY_TYPE'], prefix='DAY_TYPE')\n",
    "#missing_cols = set(['DAY_TYPE_A', 'DAY_TYPE_B', 'DAY_TYPE_C']) - set(day_type_dummies.columns)\n",
    "#for col in missing_cols:\n",
    "#    day_type_dummies[col] = False\n",
    "#TRAIN_DF = pd.concat([TRAIN_DF, day_type_dummies], axis=1)\n",
    "\n",
    "call_type_dummies = pd.get_dummies(TRAIN_DF['CALL_TYPE'], prefix='CALL_TYPE')\n",
    "missing_cols = set(['CALL_TYPE_A', 'CALL_TYPE_B', 'CALL_TYPE_C']) - set(call_type_dummies.columns)\n",
    "for col in missing_cols:\n",
    "    call_type_dummies[col] = False\n",
    "TRAIN_DF = pd.concat([TRAIN_DF, call_type_dummies], axis=1)\n",
    "\n",
    "# delete the old columns now that we don't need them anymore\n",
    "TRAIN_DF.drop('DAY_TYPE', axis=1, inplace=True)\n",
    "TRAIN_DF.drop('CALL_TYPE', axis=1, inplace=True)\n",
    "\n",
    "TRAIN_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TRIP_ID', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID', 'MISSING_DATA',\n",
      "       'POLYLINE', 'TRAVEL_TIME', 'CALL_TYPE_A', 'CALL_TYPE_B', 'CALL_TYPE_C',\n",
      "       'YEAR_2013', 'YEAR_2014', 'MONTH_1', 'MONTH_2', 'MONTH_3', 'MONTH_4',\n",
      "       'MONTH_5', 'MONTH_6', 'MONTH_7', 'MONTH_8', 'MONTH_9', 'MONTH_10',\n",
      "       'MONTH_11', 'MONTH_12', 'DAY_OF_WEEK_0', 'DAY_OF_WEEK_1',\n",
      "       'DAY_OF_WEEK_2', 'DAY_OF_WEEK_3', 'DAY_OF_WEEK_4', 'DAY_OF_WEEK_5',\n",
      "       'DAY_OF_WEEK_6', 'HOUR_0', 'HOUR_1', 'HOUR_2', 'HOUR_3', 'HOUR_4',\n",
      "       'HOUR_5', 'HOUR_6', 'HOUR_7', 'HOUR_8', 'HOUR_9', 'HOUR_10', 'HOUR_11',\n",
      "       'HOUR_12', 'HOUR_13', 'HOUR_14', 'HOUR_15', 'HOUR_16', 'HOUR_17',\n",
      "       'HOUR_18', 'HOUR_19', 'HOUR_20', 'HOUR_21', 'HOUR_22', 'HOUR_23'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Lets try to get some additional features from the timestamp column\n",
    "TRAIN_DF['TIMESTAMP'] = pd.to_datetime(TRAIN_DF['TIMESTAMP'], unit='s')\n",
    "\n",
    "# Extract year, month, day of the week, hour, and minute\n",
    "TRAIN_DF['YEAR'] = TRAIN_DF['TIMESTAMP'].dt.year\n",
    "TRAIN_DF['MONTH'] = TRAIN_DF['TIMESTAMP'].dt.month\n",
    "TRAIN_DF['DAY_OF_WEEK'] = TRAIN_DF['TIMESTAMP'].dt.dayofweek\n",
    "TRAIN_DF['HOUR'] = TRAIN_DF['TIMESTAMP'].dt.hour\n",
    "\n",
    "# One-hot encode year, month, day of the week, and hour\n",
    "TRAIN_DF = pd.concat([TRAIN_DF, pd.get_dummies(TRAIN_DF['YEAR'], prefix='YEAR')], axis=1)\n",
    "TRAIN_DF = pd.concat([TRAIN_DF, pd.get_dummies(TRAIN_DF['MONTH'], prefix='MONTH')], axis=1)\n",
    "TRAIN_DF = pd.concat([TRAIN_DF, pd.get_dummies(TRAIN_DF['DAY_OF_WEEK'], prefix='DAY_OF_WEEK')], axis=1)\n",
    "TRAIN_DF = pd.concat([TRAIN_DF, pd.get_dummies(TRAIN_DF['HOUR'], prefix='HOUR')], axis=1)\n",
    "\n",
    "\n",
    "# Drop the original TIMESTAMP and DAY_OF_WEEK columns\n",
    "TRAIN_DF.drop(['TIMESTAMP', 'DAY_OF_WEEK', 'YEAR', 'MONTH', 'HOUR'], axis=1, inplace=True)\n",
    "\n",
    "# We could do referene encoding to speed up train time in the future \n",
    "# For day of the week, Sunday is 0,0,0,0,0,0 - Monday is 1,0,0,0,0,0 - Tuesday is 0,1,0,0,0,0 - etc.\n",
    "# TRAIN_DF.drop(['DAY_OF_WEEK_0', 'MONTH_1', 'HOUR_0', 'YEAR_2013'], axis=1, inplace=True)\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "print(TRAIN_DF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000542</td>\n",
       "      <td>1408039037</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000108</td>\n",
       "      <td>1408038611</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000370</td>\n",
       "      <td>1408038568</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000492</td>\n",
       "      <td>1408039090</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20000621</td>\n",
       "      <td>1408039177</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TRIP_ID  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   TIMESTAMP  MISSING_DATA   \n",
       "0      T1          NaN          15.0  20000542  1408039037         False  \\\n",
       "1      T2          NaN          57.0  20000108  1408038611         False   \n",
       "2      T3          NaN          15.0  20000370  1408038568         False   \n",
       "3      T4          NaN          53.0  20000492  1408039090         False   \n",
       "4      T5          NaN          18.0  20000621  1408039177         False   \n",
       "\n",
       "   CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  \n",
       "0        False         True        False  \n",
       "1        False         True        False  \n",
       "2        False         True        False  \n",
       "3        False         True        False  \n",
       "4        False         True        False  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST_PUBLIC_CSV feature extraction\n",
    "call_type_dummies = pd.get_dummies(TEST_PUBLIC_DF['CALL_TYPE'], prefix='CALL_TYPE')\n",
    "missing_cols = set(['CALL_TYPE_A', 'CALL_TYPE_B', 'CALL_TYPE_C']) - set(call_type_dummies.columns)\n",
    "for col in missing_cols:\n",
    "    call_type_dummies[col] = False\n",
    "TEST_PUBLIC_DF = pd.concat([TEST_PUBLIC_DF, call_type_dummies], axis=1)\n",
    "\n",
    "# delete the old columns now that we don't need them anymore\n",
    "TEST_PUBLIC_DF.drop('DAY_TYPE', axis=1, inplace=True)\n",
    "TEST_PUBLIC_DF.drop('CALL_TYPE', axis=1, inplace=True)\n",
    "\n",
    "TEST_PUBLIC_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to get some additional features from the timestamp column\n",
    "hour_columns = ['HOUR_' + str(i) for i in range(24)]\n",
    "day_columns = ['DAY_OF_WEEK_' + str(i) for i in range(7)]\n",
    "month_columns = ['MONTH_' + str(i) for i in range(1,13)]\n",
    "year_columns = ['YEAR_2013', 'YEAR_2014']\n",
    "\n",
    "TEST_PUBLIC_DF['TIMESTAMP'] = pd.to_datetime(TEST_PUBLIC_DF['TIMESTAMP'], unit='s')\n",
    "\n",
    "# Extract year, month, day of the week, hour, and minute\n",
    "TEST_PUBLIC_DF['YEAR'] = TEST_PUBLIC_DF['TIMESTAMP'].dt.year\n",
    "TEST_PUBLIC_DF['MONTH'] = TEST_PUBLIC_DF['TIMESTAMP'].dt.month\n",
    "TEST_PUBLIC_DF['DAY_OF_WEEK'] = TEST_PUBLIC_DF['TIMESTAMP'].dt.dayofweek\n",
    "TEST_PUBLIC_DF['HOUR'] = TEST_PUBLIC_DF['TIMESTAMP'].dt.hour\n",
    "\n",
    "# One-hot encode year, month, day of the week, and hour\n",
    "TEST_PUBLIC_DF = pd.concat([TEST_PUBLIC_DF, pd.get_dummies(TEST_PUBLIC_DF['YEAR'], prefix='YEAR')], axis=1)\n",
    "TEST_PUBLIC_DF = pd.concat([TEST_PUBLIC_DF, pd.get_dummies(TEST_PUBLIC_DF['MONTH'], prefix='MONTH')], axis=1)\n",
    "TEST_PUBLIC_DF = pd.concat([TEST_PUBLIC_DF, pd.get_dummies(TEST_PUBLIC_DF['DAY_OF_WEEK'], prefix='DAY_OF_WEEK')], axis=1)\n",
    "TEST_PUBLIC_DF = pd.concat([TEST_PUBLIC_DF, pd.get_dummies(TEST_PUBLIC_DF['HOUR'], prefix='HOUR')], axis=1)\n",
    "\n",
    "# Fill missing dummy columns with False\n",
    "for column in hour_columns:\n",
    "    if column not in TEST_PUBLIC_DF.columns:\n",
    "        TEST_PUBLIC_DF[column] = False\n",
    "\n",
    "for column in day_columns:\n",
    "    if column not in TEST_PUBLIC_DF.columns:\n",
    "        TEST_PUBLIC_DF[column] = False\n",
    "\n",
    "for column in month_columns:\n",
    "    if column not in TEST_PUBLIC_DF.columns:\n",
    "        TEST_PUBLIC_DF[column] = False\n",
    "\n",
    "for column in year_columns:\n",
    "    if column not in TEST_PUBLIC_DF.columns:\n",
    "        TEST_PUBLIC_DF[column] = False\n",
    "\n",
    "# Drop the original TIMESTAMP and DAY_OF_WEEK columns\n",
    "TEST_PUBLIC_DF.drop(['TIMESTAMP', 'DAY_OF_WEEK', 'YEAR', 'MONTH', 'HOUR'], axis=1, inplace=True)\n",
    "TEST_PUBLIC_DF = TEST_PUBLIC_DF.reindex(columns=TRAIN_DF.columns)\n",
    "TEST_PUBLIC_DF = TEST_PUBLIC_DF.drop(\"TRAVEL_TIME\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_train_zip = '../data/clean_data/class-competition.zip'\n",
    "\n",
    "with zipfile.ZipFile(modified_train_zip, 'w') as zip:\n",
    "    zip.writestr(\"train.csv\", TRAIN_DF.to_csv(index=False))\n",
    "    zip.writestr(\"test_public.csv\", TEST_PUBLIC_DF.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_similarity_score(hour1, hour2):\n",
    "    return (12 - min(abs(hour1-hour2), 24 - abs(hour1 - hour2)))/12\n",
    "def day_of_week_similarity_score(day1, day2):\n",
    "    cat1 = 0\n",
    "    cat2 = 0\n",
    "    type_of_day = [[5,6], [1,2,3], [0], [4]]\n",
    "    for i, tod in enumerate(type_of_day):\n",
    "        if day1 in tod:\n",
    "            cat1 = i\n",
    "        if day2 in tod:\n",
    "            cat2 = i\n",
    "    if cat1 == cat2:\n",
    "        return ((3.5 - min(abs(day1-day2), 7 - abs(day1 - day2)))/3.5)\n",
    "    elif cat1 == 0 or cat2 == 0:\n",
    "        return ((3.5 - min(abs(day1-day2), 7 - abs(day1 - day2)))/3.5) * 0.2\n",
    "    else:\n",
    "        return ((3.5 - min(abs(day1-day2), 7 - abs(day1 - day2)))/3.5) * 0.4\n",
    "def month_similarity_score(month1, month2):\n",
    "    return (6 - min(abs(month1-month2), 12 - abs(month1 - month2)))/6\n",
    "def day_of_month_similarity_score(day1, day2):\n",
    "    return (15 - min(abs(day1-day2), 30 - abs(day1 - day2)))/15\n",
    "def year_similarity_score(year1, year2):\n",
    "    return year1 == year2\n",
    "def call_type_similarity_score(type1, type2):\n",
    "    return type1 == type2\n",
    "\n",
    "#Takes in 2-tuple: (datatime object, call_type)\n",
    "def get_similarity_score(dt1, dt2):\n",
    "    hour1 = dt1[0].hour\n",
    "    hour2 = dt2[0].hour\n",
    "    week_day1 = dt1[0].weekday()\n",
    "    week_day2 = dt2[0].weekday()\n",
    "    month1 = dt1[0].month\n",
    "    month2 = dt2[0].month    \n",
    "    \n",
    "    score =  hour_similarity_score(hour1, hour2) * 0.35\n",
    "    score += day_of_week_similarity_score(week_day1, week_day2) * 0.3\n",
    "    score += month_similarity_score(month1, month2) * 0.05\n",
    "    score += call_type_similarity_score(dt1[1], dt2[1]) * 0.3\n",
    "    return score\n",
    "\n",
    "train_preprocess_data = []\n",
    "test_preprocess_data = []\n",
    "\n",
    "#preprocess and create datetime objects for all datapoints\n",
    "for i in range(len(TRAIN_DF[\"TIMESTAMP\"])):\n",
    "    val = datetime.fromtimestamp(TRAIN_DF.iloc[i][\"TIMESTAMP\"])\n",
    "    val2 = TRAIN_DF.iloc[i][\"CALL_TYPE\"]\n",
    "    train_preprocess_data.append([val, val2])\n",
    "for i in range(len(TEST_PUBLIC_DF[\"TIMESTAMP\"])):\n",
    "    val = datetime.fromtimestamp(TEST_PUBLIC_DF.iloc[i][\"TIMESTAMP\"])\n",
    "    val2 = TEST_PUBLIC_DF.iloc[i][\"CALL_TYPE\"]\n",
    "    test_preprocess_data.append([val, val2])\n",
    "\n",
    "#iterate through all test data and train data to find similar datapoints\n",
    "similar_train_data_vals = set()\n",
    "for i in range(len(test_preprocess_data)):\n",
    "    print(i)\n",
    "    similarity_scores = []\n",
    "    for j in range(len(train_preprocess_data)):\n",
    "        if j not in similar_train_data_vals:\n",
    "            similarity_scores.append([get_similarity_score(test_preprocess_data[i], train_preprocess_data[j]), j])\n",
    "    similarity_scores.sort(reverse = True)\n",
    "    similar_train_data_vals.update(similarity_scores[k][1] for k in range(50))\n",
    "\n",
    "similar_train_data_vals_list = list(similar_train_data_vals)\n",
    "similar_train_data_vals_list.sort()\n",
    "\n",
    "new_df = TRAIN_DF.iloc[0:0]\n",
    "for val in similar_train_data_vals_list:\n",
    "    new_df = new_df.append(TRAIN_DF.iloc[val])\n",
    "\n",
    "#save dataset\n",
    "# new_df.to_csv('representative_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
