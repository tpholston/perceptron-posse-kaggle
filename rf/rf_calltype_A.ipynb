{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import math\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "\n",
    "# data_preparation.ipynb created train.zip which has train.csv inside\n",
    "zipped_data_path = \"../data/clean_data/class-competition-cleaned.zip\"\n",
    "train_csv = \"train_call_type_A.csv\"\n",
    "test_csv = \"test_public.csv\"\n",
    "\n",
    "with zipfile.ZipFile(zipped_data_path, \"r\") as zipf:\n",
    "    train_data = pd.read_csv(zipf.open(train_csv))\n",
    "    test_data = pd.read_csv(zipf.open(test_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>START_LOCATION</th>\n",
       "      <th>MON_sin</th>\n",
       "      <th>MON_cos</th>\n",
       "      <th>DAY_sin</th>\n",
       "      <th>DAY_cos</th>\n",
       "      <th>HR_sin</th>\n",
       "      <th>HR_cos</th>\n",
       "      <th>WK_sin</th>\n",
       "      <th>WK_cos</th>\n",
       "      <th>YR_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000542</td>\n",
       "      <td>41.1486275073,-8.58587660305</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000108</td>\n",
       "      <td>41.1457188058,-8.61070701502</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000370</td>\n",
       "      <td>41.1486275073,-8.58587660305</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000492</td>\n",
       "      <td>41.1412081961,-8.61401226127</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20000621</td>\n",
       "      <td>41.1483209068,-8.61960347647</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   \n",
       "0      T1         B          NaN          15.0  20000542  \\\n",
       "1      T2         B          NaN          57.0  20000108   \n",
       "2      T3         B          NaN          15.0  20000370   \n",
       "3      T4         B          NaN          53.0  20000492   \n",
       "4      T5         B          NaN          18.0  20000621   \n",
       "\n",
       "                 START_LOCATION   MON_sin  MON_cos   DAY_sin   DAY_cos   \n",
       "0  41.1486275073,-8.58587660305 -0.866025     -0.5  0.299363 -0.954139  \\\n",
       "1  41.1457188058,-8.61070701502 -0.866025     -0.5  0.299363 -0.954139   \n",
       "2  41.1486275073,-8.58587660305 -0.866025     -0.5  0.299363 -0.954139   \n",
       "3  41.1412081961,-8.61401226127 -0.866025     -0.5  0.299363 -0.954139   \n",
       "4  41.1483209068,-8.61960347647 -0.866025     -0.5  0.299363 -0.954139   \n",
       "\n",
       "   HR_sin    HR_cos    WK_sin    WK_cos  YR_2013  \n",
       "0     0.5 -0.866025  0.433884 -0.900969    False  \n",
       "1     0.5 -0.866025  0.433884 -0.900969    False  \n",
       "2     0.5 -0.866025  0.433884 -0.900969    False  \n",
       "3     0.5 -0.866025  0.433884 -0.900969    False  \n",
       "4     0.5 -0.866025  0.433884 -0.900969    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only data points with CALL_TYPE B\n",
    "test_data = test_data[test_data['CALL_TYPE'] == 'B']\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 346466 entries, 0 to 346465\n",
      "Data columns (total 21 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   TRIP_ID                          346466 non-null  int64  \n",
      " 1   CALL_TYPE                        346466 non-null  object \n",
      " 2   ORIGIN_CALL                      346466 non-null  float64\n",
      " 3   ORIGIN_STAND                     0 non-null       float64\n",
      " 4   TAXI_ID                          346466 non-null  int64  \n",
      " 5   POLYLINE                         346466 non-null  object \n",
      " 6   TRAVEL_TIME                      346466 non-null  int64  \n",
      " 7   START_LOCATION                   0 non-null       float64\n",
      " 8   MON_sin                          346466 non-null  float64\n",
      " 9   MON_cos                          346466 non-null  float64\n",
      " 10  DAY_sin                          346466 non-null  float64\n",
      " 11  DAY_cos                          346466 non-null  float64\n",
      " 12  HR_sin                           346466 non-null  float64\n",
      " 13  HR_cos                           346466 non-null  float64\n",
      " 14  WK_sin                           346466 non-null  float64\n",
      " 15  WK_cos                           346466 non-null  float64\n",
      " 16  YR_2013                          346466 non-null  bool   \n",
      " 17  TAXI_ID_MEAN_ENC                 346466 non-null  float64\n",
      " 18  ORIGIN_CALL_MEAN_ENC             346466 non-null  float64\n",
      " 19  TAXI_ID_MEAN_ENC_NORMALIZED      346466 non-null  float64\n",
      " 20  ORIGIN_CALL_MEAN_ENC_NORMALIZED  346466 non-null  float64\n",
      "dtypes: bool(1), float64(15), int64(3), object(2)\n",
      "memory usage: 53.2+ MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "mean_encoding_taxi = train_data.groupby('TAXI_ID')['TRAVEL_TIME'].mean().reset_index()\n",
    "mean_encoding_call = train_data.groupby('ORIGIN_CALL')['TRAVEL_TIME'].mean().reset_index()\n",
    "\n",
    "# Create a dictionary mapping 'TAXI_ID' to mean 'TRAVEL_TIME' value\n",
    "mean_encoding_taxi_dict = dict(zip(mean_encoding_taxi['TAXI_ID'], mean_encoding_taxi['TRAVEL_TIME']))\n",
    "\n",
    "# Create a dictionary mapping 'ORIGIN_CALL' to mean 'TRAVEL_TIME' value\n",
    "mean_encoding_call_dict = dict(zip(mean_encoding_call['ORIGIN_CALL'], mean_encoding_call['TRAVEL_TIME']))\n",
    "\n",
    "# Replace the 'TAXI_ID' values with mean target encoding values\n",
    "train_data.loc[:, 'TAXI_ID_MEAN_ENC'] = train_data['TAXI_ID'].map(mean_encoding_taxi_dict)\n",
    "test_data.loc[:, 'TAXI_ID_MEAN_ENC'] = test_data['TAXI_ID'].map(mean_encoding_taxi_dict)\n",
    "\n",
    "# Replace the 'ORIGIN_CALL' values with mean target encoding values\n",
    "train_data.loc[:, 'ORIGIN_CALL_MEAN_ENC'] = train_data['ORIGIN_CALL'].map(mean_encoding_call_dict)\n",
    "test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC'] = test_data['ORIGIN_CALL'].map(mean_encoding_call_dict)\n",
    "\n",
    "overall_mean_enc = train_data['ORIGIN_CALL_MEAN_ENC'].mean()\n",
    "test_data['ORIGIN_CALL_MEAN_ENC'].fillna(overall_mean_enc, inplace=True)\n",
    "\n",
    "mean_taxi_enc_train = pd.DataFrame(train_data['TAXI_ID_MEAN_ENC'])\n",
    "mean_taxi_enc_test = pd.DataFrame(test_data['TAXI_ID_MEAN_ENC'])\n",
    "mean_call_enc_train = pd.DataFrame(train_data['ORIGIN_CALL_MEAN_ENC'])\n",
    "mean_call_enc_test = pd.DataFrame(test_data['ORIGIN_CALL_MEAN_ENC'])\n",
    "\n",
    "# Initialize StandardScaler and fit it on the mean encoding column\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(mean_taxi_enc_train)\n",
    "\n",
    "# Transform the mean encoding column using the fitted scaler\n",
    "normalized_taxi_enc_train = scaler.transform(mean_taxi_enc_train)\n",
    "normalized_taxi_enc_test = scaler.transform(mean_taxi_enc_test)\n",
    "\n",
    "# Replace the original mean encoding column with the normalized values\n",
    "train_data.loc[:, 'TAXI_ID_MEAN_ENC_NORMALIZED'] = normalized_taxi_enc_train\n",
    "test_data.loc[:, 'TAXI_ID_MEAN_ENC_NORMALIZED'] = normalized_taxi_enc_test\n",
    "\n",
    "# Initialize StandardScaler and fit it on the mean encoding column\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(mean_call_enc_train)\n",
    "\n",
    "# Transform the mean encoding column using the fitted scaler\n",
    "normalized_call_enc_train = scaler.transform(mean_call_enc_train)\n",
    "normalized_call_enc_test = scaler.transform(mean_call_enc_test)\n",
    "\n",
    "# Replace the original mean encoding column with the normalized values\n",
    "train_data.loc[:, 'ORIGIN_CALL_MEAN_ENC_NORMALIZED'] = normalized_call_enc_train\n",
    "test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC_NORMALIZED'] = normalized_call_enc_test\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We could totally change this. Utilization of these just probably requires further preprocessing.\n",
    "ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION = ['TRIP_ID', 'CALL_TYPE', 'ORIGIN_STAND', 'POLYLINE', 'START_LOCATION', 'ORIGIN_CALL', 'TAXI_ID', 'ORIGIN_CALL_MEAN_ENC', 'TAXI_ID_MEAN_ENC']\n",
    "\n",
    "train_data_sample = train_data.sample(frac=0.8, random_state=420) # frac is used to control percentage of train data used\n",
    "X = train_data_sample.drop(\"TRAVEL_TIME\", axis=1)\n",
    "X = X.loc[:, ~X.columns.isin(ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION)]\n",
    "y = train_data_sample[\"TRAVEL_TIME\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=420)\n",
    "\n",
    "test_features = test_data.loc[:, ~test_data.columns.isin(ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=420, max_features='sqrt', n_estimators = 1200, min_samples_leaf=4, min_samples_split=10, max_depth=60, bootstrap=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317.4090789825179"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "root_mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318.8616716223454"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRFRegressor\n",
    "\n",
    "model = XGBRFRegressor(n_estimators=1200, colsample_bynode=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "root_mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num trees:  10\n",
      "colsample_bynode:  0.1 | RMSE:  371.71444965498233\n",
      "colsample_bynode:  0.30000000000000004 | RMSE:  325.52322223156284\n",
      "colsample_bynode:  0.5000000000000001 | RMSE:  321.1265959018283\n",
      "colsample_bynode:  0.7000000000000001 | RMSE:  319.1493216136946\n",
      "colsample_bynode:  0.9000000000000001 | RMSE:  319.1390414815367\n",
      "Num trees:  50\n",
      "colsample_bynode:  0.1 | RMSE:  360.3202152027043\n",
      "colsample_bynode:  0.30000000000000004 | RMSE:  329.3915865121829\n",
      "colsample_bynode:  0.5000000000000001 | RMSE:  321.63492056943\n",
      "colsample_bynode:  0.7000000000000001 | RMSE:  319.31030045976615\n",
      "colsample_bynode:  0.9000000000000001 | RMSE:  318.971755248209\n",
      "Num trees:  100\n",
      "colsample_bynode:  0.1 | RMSE:  358.8260328378554\n",
      "colsample_bynode:  0.30000000000000004 | RMSE:  328.45256037440595\n",
      "colsample_bynode:  0.5000000000000001 | RMSE:  321.0969674007282\n",
      "colsample_bynode:  0.7000000000000001 | RMSE:  319.130423067615\n",
      "colsample_bynode:  0.9000000000000001 | RMSE:  318.9244420934945\n",
      "Num trees:  500\n",
      "colsample_bynode:  0.1 | RMSE:  357.8460282479775\n",
      "colsample_bynode:  0.30000000000000004 | RMSE:  329.249805119639\n",
      "colsample_bynode:  0.5000000000000001 | RMSE:  321.11257896012796\n",
      "colsample_bynode:  0.7000000000000001 | RMSE:  319.0049818594912\n",
      "colsample_bynode:  0.9000000000000001 | RMSE:  318.91086702278966\n",
      "Num trees:  1200\n",
      "colsample_bynode:  0.1 | RMSE:  356.07360309106855\n",
      "colsample_bynode:  0.30000000000000004 | RMSE:  328.9058623590709\n",
      "colsample_bynode:  0.5000000000000001 | RMSE:  320.87729783539646\n",
      "colsample_bynode:  0.7000000000000001 | RMSE:  318.9911258932103\n",
      "colsample_bynode:  0.9000000000000001 | RMSE:  318.9201274817436\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRFRegressor\n",
    "from numpy import arange\n",
    "# TAKES ~4 MIN 30 SEC ON M1 PRO CPU\n",
    "n_trees = [10, 50, 100, 500, 1200]\n",
    "models = dict()\n",
    "for v in n_trees:\n",
    "    print('Num trees: ', v)\n",
    "    for b in arange(0.1, 1.1, 0.2):\n",
    "        models[str(v)] = XGBRFRegressor(n_estimators=v, colsample_bynode=b)\n",
    "        models[str(v)].fit(X_train, y_train)\n",
    "        y_pred = models[str(v)].predict(X_test)\n",
    "        print('colsample_bynode: ', b, '| RMSE: ', root_mean_squared_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
