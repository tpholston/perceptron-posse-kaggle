{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import math\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "\n",
    "# data_preparation.ipynb created train.zip which has train.csv inside\n",
    "zipped_data_path = \"../data/clean_data/class-competition-cleaned.zip\"\n",
    "train_csv = \"train_call_type_A.csv\"\n",
    "test_csv = \"test_public.csv\"\n",
    "\n",
    "with zipfile.ZipFile(zipped_data_path, \"r\") as zipf:\n",
    "    train_data = pd.read_csv(zipf.open(train_csv))\n",
    "    test_data = pd.read_csv(zipf.open(test_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>START_LOCATION</th>\n",
       "      <th>MON_sin</th>\n",
       "      <th>MON_cos</th>\n",
       "      <th>DAY_sin</th>\n",
       "      <th>DAY_cos</th>\n",
       "      <th>HR_sin</th>\n",
       "      <th>HR_cos</th>\n",
       "      <th>WK_sin</th>\n",
       "      <th>WK_cos</th>\n",
       "      <th>DATE_2014-08-14</th>\n",
       "      <th>DATE_2014-09-30</th>\n",
       "      <th>DATE_2014-10-06</th>\n",
       "      <th>DATE_2014-10-31</th>\n",
       "      <th>DATE_2014-12-21</th>\n",
       "      <th>YR_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>A</td>\n",
       "      <td>42612.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T8</td>\n",
       "      <td>A</td>\n",
       "      <td>31780.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>T22</td>\n",
       "      <td>A</td>\n",
       "      <td>85698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>T23</td>\n",
       "      <td>A</td>\n",
       "      <td>37007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>T37</td>\n",
       "      <td>A</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID START_LOCATION   \n",
       "5       T6         A      42612.0           NaN  20000607            NaN  \\\n",
       "7       T8         A      31780.0           NaN  20000619            NaN   \n",
       "21     T22         A      85698.0           NaN  20000199            NaN   \n",
       "22     T23         A      37007.0           NaN  20000480            NaN   \n",
       "36     T37         A       2002.0           NaN  20000159            NaN   \n",
       "\n",
       "     MON_sin  MON_cos   DAY_sin   DAY_cos  HR_sin    HR_cos    WK_sin   \n",
       "5  -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025  0.433884  \\\n",
       "7  -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025  0.433884   \n",
       "21 -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025  0.433884   \n",
       "22 -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025  0.433884   \n",
       "36 -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025  0.433884   \n",
       "\n",
       "      WK_cos  DATE_2014-08-14  DATE_2014-09-30  DATE_2014-10-06   \n",
       "5  -0.900969             True            False            False  \\\n",
       "7  -0.900969             True            False            False   \n",
       "21 -0.900969             True            False            False   \n",
       "22 -0.900969             True            False            False   \n",
       "36 -0.900969             True            False            False   \n",
       "\n",
       "    DATE_2014-10-31  DATE_2014-12-21  YR_2013  \n",
       "5             False            False    False  \n",
       "7             False            False    False  \n",
       "21            False            False    False  \n",
       "22            False            False    False  \n",
       "36            False            False    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only data points with CALL_TYPE A\n",
    "test_data = test_data[test_data['CALL_TYPE'] == 'A']\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17032 entries, 0 to 17031\n",
      "Data columns (total 27 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   TRIP_ID                          17032 non-null  int64  \n",
      " 1   CALL_TYPE                        17032 non-null  object \n",
      " 2   ORIGIN_CALL                      17032 non-null  float64\n",
      " 3   ORIGIN_STAND                     0 non-null      float64\n",
      " 4   TAXI_ID                          17032 non-null  int64  \n",
      " 5   POLYLINE                         17032 non-null  object \n",
      " 6   TRAVEL_TIME                      17032 non-null  int64  \n",
      " 7   START_LOCATION                   0 non-null      float64\n",
      " 8   MON_sin                          17032 non-null  float64\n",
      " 9   MON_cos                          17032 non-null  float64\n",
      " 10  DAY_sin                          17032 non-null  float64\n",
      " 11  DAY_cos                          17032 non-null  float64\n",
      " 12  HR_sin                           17032 non-null  float64\n",
      " 13  HR_cos                           17032 non-null  float64\n",
      " 14  WK_sin                           17032 non-null  float64\n",
      " 15  WK_cos                           17032 non-null  float64\n",
      " 16  YR_2013                          17032 non-null  bool   \n",
      " 17  DATE                             17032 non-null  object \n",
      " 18  DATE_2014-08-14                  17032 non-null  bool   \n",
      " 19  DATE_2014-09-30                  17032 non-null  bool   \n",
      " 20  DATE_2014-10-06                  17032 non-null  bool   \n",
      " 21  DATE_2014-10-31                  17032 non-null  bool   \n",
      " 22  DATE_2014-12-21                  17032 non-null  bool   \n",
      " 23  TAXI_ID_MEAN_ENC                 17032 non-null  float64\n",
      " 24  ORIGIN_CALL_MEAN_ENC             17032 non-null  float64\n",
      " 25  TAXI_ID_MEAN_ENC_NORMALIZED      17032 non-null  float64\n",
      " 26  ORIGIN_CALL_MEAN_ENC_NORMALIZED  17032 non-null  float64\n",
      "dtypes: bool(6), float64(15), int64(3), object(3)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "mean_encoding_taxi = train_data.groupby('TAXI_ID')['TRAVEL_TIME'].mean().reset_index()\n",
    "mean_encoding_call = train_data.groupby('ORIGIN_CALL')['TRAVEL_TIME'].mean().reset_index()\n",
    "\n",
    "# Create a dictionary mapping 'TAXI_ID' to mean 'TRAVEL_TIME' value\n",
    "mean_encoding_taxi_dict = dict(zip(mean_encoding_taxi['TAXI_ID'], mean_encoding_taxi['TRAVEL_TIME']))\n",
    "\n",
    "# Create a dictionary mapping 'ORIGIN_CALL' to mean 'TRAVEL_TIME' value\n",
    "mean_encoding_call_dict = dict(zip(mean_encoding_call['ORIGIN_CALL'], mean_encoding_call['TRAVEL_TIME']))\n",
    "\n",
    "# Replace the 'TAXI_ID' values with mean target encoding values\n",
    "train_data.loc[:, 'TAXI_ID_MEAN_ENC'] = train_data['TAXI_ID'].map(mean_encoding_taxi_dict)\n",
    "test_data.loc[:, 'TAXI_ID_MEAN_ENC'] = test_data['TAXI_ID'].map(mean_encoding_taxi_dict)\n",
    "\n",
    "# Replace the 'ORIGIN_CALL' values with mean target encoding values\n",
    "train_data.loc[:, 'ORIGIN_CALL_MEAN_ENC'] = train_data['ORIGIN_CALL'].map(mean_encoding_call_dict)\n",
    "test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC'] = test_data['ORIGIN_CALL'].map(mean_encoding_call_dict)\n",
    "\n",
    "overall_mean_enc = train_data['ORIGIN_CALL_MEAN_ENC'].mean()\n",
    "test_data['ORIGIN_CALL_MEAN_ENC'].fillna(overall_mean_enc, inplace=True)\n",
    "\n",
    "mean_taxi_enc_train = pd.DataFrame(train_data['TAXI_ID_MEAN_ENC'])\n",
    "mean_taxi_enc_test = pd.DataFrame(test_data['TAXI_ID_MEAN_ENC'])\n",
    "mean_call_enc_train = pd.DataFrame(train_data['ORIGIN_CALL_MEAN_ENC'])\n",
    "mean_call_enc_test = pd.DataFrame(test_data['ORIGIN_CALL_MEAN_ENC'])\n",
    "\n",
    "# Initialize StandardScaler and fit it on the mean encoding column\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(mean_taxi_enc_train)\n",
    "\n",
    "# Transform the mean encoding column using the fitted scaler\n",
    "normalized_taxi_enc_train = scaler.transform(mean_taxi_enc_train)\n",
    "normalized_taxi_enc_test = scaler.transform(mean_taxi_enc_test)\n",
    "\n",
    "# Replace the original mean encoding column with the normalized values\n",
    "train_data.loc[:, 'TAXI_ID_MEAN_ENC_NORMALIZED'] = normalized_taxi_enc_train\n",
    "test_data.loc[:, 'TAXI_ID_MEAN_ENC_NORMALIZED'] = normalized_taxi_enc_test\n",
    "\n",
    "# Initialize StandardScaler and fit it on the mean encoding column\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(mean_call_enc_train)\n",
    "\n",
    "# Transform the mean encoding column using the fitted scaler\n",
    "normalized_call_enc_train = scaler.transform(mean_call_enc_train)\n",
    "normalized_call_enc_test = scaler.transform(mean_call_enc_test)\n",
    "\n",
    "# Replace the original mean encoding column with the normalized values\n",
    "train_data.loc[:, 'ORIGIN_CALL_MEAN_ENC_NORMALIZED'] = normalized_call_enc_train\n",
    "test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC_NORMALIZED'] = normalized_call_enc_test\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We could totally change this. Utilization of these just probably requires further preprocessing.\n",
    "ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION = ['TRIP_ID', 'CALL_TYPE', 'ORIGIN_STAND', 'POLYLINE', 'START_LOCATION', 'ORIGIN_CALL', 'TAXI_ID', 'ORIGIN_CALL_MEAN_ENC', 'TAXI_ID_MEAN_ENC', 'DATE']\n",
    "\n",
    "X = train_data.drop(\"TRAVEL_TIME\", axis=1)\n",
    "X = X.loc[:, ~X.columns.isin(ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION)]\n",
    "y = train_data[\"TRAVEL_TIME\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=420, shuffle=True)\n",
    "\n",
    "test_features = test_data.loc[:, ~test_data.columns.isin(ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_features.reindex(columns=X.columns)\n",
    "test_features = test_features.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=420, max_features='sqrt', n_estimators = 1200, min_samples_leaf=4, min_samples_split=10, max_depth=60, bootstrap=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302.3720564977033"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "root_mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction_to_csv(y_pred, outfile_name):\n",
    "\toutput_df = pd.DataFrame(test_data[\"TRIP_ID\"])\n",
    "\toutput_df[\"TRAVEL_TIME\"] = y_pred\n",
    "\toutput_df.head()\n",
    "\toutput_df.to_csv(f'../guesses/{outfile_name}', index=False)\n",
    "\t\n",
    "y_pred = rf.predict(test_features)\n",
    "test_prediction_to_csv(y_pred, \"predicting_random_forest_calltype_A.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345.1656089882059"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRFRegressor\n",
    "\n",
    "model = XGBRFRegressor(n_estimators=1200, colsample_bynode=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "root_mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num trees:  10\n",
      "colsample_bynode:  0.1 | RMSE:  408.9788070157798\n",
      "colsample_bynode:  0.30000000000000004 | RMSE:  330.8198917215895\n",
      "colsample_bynode:  0.5000000000000001 | RMSE:  299.7516048622163\n",
      "colsample_bynode:  0.7000000000000001 | RMSE:  299.54365753896474\n",
      "colsample_bynode:  0.9000000000000001 | RMSE:  299.2938581052686\n",
      "Num trees:  50\n",
      "colsample_bynode:  0.1 | RMSE:  407.09765506042976\n",
      "colsample_bynode:  0.30000000000000004 | RMSE:  326.3769366520978\n",
      "colsample_bynode:  0.5000000000000001 | RMSE:  302.68190764107067\n",
      "colsample_bynode:  0.7000000000000001 | RMSE:  298.45777935835827\n",
      "colsample_bynode:  0.9000000000000001 | RMSE:  299.1114466849732\n",
      "Num trees:  100\n",
      "colsample_bynode:  0.1 | RMSE:  405.42566415720086\n",
      "colsample_bynode:  0.30000000000000004 | RMSE:  329.453654017603\n",
      "colsample_bynode:  0.5000000000000001 | RMSE:  303.7059707303956\n",
      "colsample_bynode:  0.7000000000000001 | RMSE:  298.7862202197568\n",
      "colsample_bynode:  0.9000000000000001 | RMSE:  299.2119897922542\n",
      "Num trees:  500\n",
      "colsample_bynode:  0.1 | RMSE:  405.93354539054167\n",
      "colsample_bynode:  0.30000000000000004 | RMSE:  329.31025755354295\n",
      "colsample_bynode:  0.5000000000000001 | RMSE:  302.28723149390555\n",
      "colsample_bynode:  0.7000000000000001 | RMSE:  298.86634000690094\n",
      "colsample_bynode:  0.9000000000000001 | RMSE:  299.0080713292431\n",
      "Num trees:  1200\n",
      "colsample_bynode:  0.1 | RMSE:  404.1543844093437\n",
      "colsample_bynode:  0.30000000000000004 | RMSE:  328.5213725133334\n",
      "colsample_bynode:  0.5000000000000001 | RMSE:  301.5949800669061\n",
      "colsample_bynode:  0.7000000000000001 | RMSE:  298.76755658796714\n",
      "colsample_bynode:  0.9000000000000001 | RMSE:  299.0457552773335\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRFRegressor\n",
    "from numpy import arange\n",
    "# TAKES ~4 MIN 30 SEC ON M1 PRO CPU\n",
    "n_trees = [10, 50, 100, 500, 1200]\n",
    "models = dict()\n",
    "for v in n_trees:\n",
    "    print('Num trees: ', v)\n",
    "    for b in arange(0.1, 1.1, 0.2):\n",
    "        models[str(v)] = XGBRFRegressor(n_estimators=v, colsample_bynode=b)\n",
    "        models[str(v)].fit(X_train, y_train)\n",
    "        y_pred = models[str(v)].predict(X_test)\n",
    "        print('colsample_bynode: ', b, '| RMSE: ', root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_features)\n",
    "test_prediction_to_csv(y_pred, \"predicting_rf_xgboost_calltype_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
