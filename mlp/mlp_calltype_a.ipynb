{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE: train_call_type_A.csv\n",
      "FILE: train_call_type_B.csv\n",
      "FILE: train_call_type_C.csv\n",
      "FILE: test_public.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import math\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "\n",
    "zipped_data_path = \"../data/clean_data/class-competition-cleaned.zip\"\n",
    "\n",
    "dataframes = defaultdict(pd.DataFrame)\n",
    "with zipfile.ZipFile(zipped_data_path, \"r\") as zipf:\n",
    "    for filename in zipf.namelist():\n",
    "        if filename.endswith(\".csv\"):\n",
    "            with zipf.open(filename) as f:\n",
    "                dataframes.update({ filename : pd.read_csv(io.TextIOWrapper(f)) })\n",
    "\n",
    "                # Lets take a look at the files\n",
    "                print(f\"FILE: {filename}\")\n",
    "                # If you want to see file info uncomment this:\n",
    "                # display(dataframes[filename].info())\n",
    "                # display(dataframes[filename].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "      <th>START_LOCATION</th>\n",
       "      <th>MON_sin</th>\n",
       "      <th>MON_cos</th>\n",
       "      <th>DAY_sin</th>\n",
       "      <th>DAY_cos</th>\n",
       "      <th>HR_sin</th>\n",
       "      <th>HR_cos</th>\n",
       "      <th>WK_sin</th>\n",
       "      <th>WK_cos</th>\n",
       "      <th>YR_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372637343620000571</td>\n",
       "      <td>A</td>\n",
       "      <td>31508.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000571</td>\n",
       "      <td>[[-8.618868,41.155101],[-8.6175,41.154912],[-8...</td>\n",
       "      <td>465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372639135620000570</td>\n",
       "      <td>A</td>\n",
       "      <td>33180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000570</td>\n",
       "      <td>[[-8.666757,41.174055],[-8.666784,41.174064],[...</td>\n",
       "      <td>270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372637254620000657</td>\n",
       "      <td>A</td>\n",
       "      <td>39233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000657</td>\n",
       "      <td>[[-8.660646,41.168574],[-8.661087,41.167926],[...</td>\n",
       "      <td>630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372637658620000596</td>\n",
       "      <td>A</td>\n",
       "      <td>22864.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000596</td>\n",
       "      <td>[[-8.665686,41.170626],[-8.665677,41.170653],[...</td>\n",
       "      <td>375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372639535620000161</td>\n",
       "      <td>A</td>\n",
       "      <td>25862.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000161</td>\n",
       "      <td>[[-8.648226,41.148333],[-8.648514,41.148297],[...</td>\n",
       "      <td>840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   \n",
       "0  1372637343620000571         A      31508.0           NaN  20000571  \\\n",
       "1  1372639135620000570         A      33180.0           NaN  20000570   \n",
       "2  1372637254620000657         A      39233.0           NaN  20000657   \n",
       "3  1372637658620000596         A      22864.0           NaN  20000596   \n",
       "4  1372639535620000161         A      25862.0           NaN  20000161   \n",
       "\n",
       "                                            POLYLINE  TRAVEL_TIME   \n",
       "0  [[-8.618868,41.155101],[-8.6175,41.154912],[-8...          465  \\\n",
       "1  [[-8.666757,41.174055],[-8.666784,41.174064],[...          270   \n",
       "2  [[-8.660646,41.168574],[-8.661087,41.167926],[...          630   \n",
       "3  [[-8.665686,41.170626],[-8.665677,41.170653],[...          375   \n",
       "4  [[-8.648226,41.148333],[-8.648514,41.148297],[...          840   \n",
       "\n",
       "   START_LOCATION       MON_sin  MON_cos   DAY_sin  DAY_cos    HR_sin   \n",
       "0             NaN  1.224647e-16     -1.0 -0.201299  0.97953 -0.965926  \\\n",
       "1             NaN  1.224647e-16     -1.0 -0.201299  0.97953 -0.965926   \n",
       "2             NaN  1.224647e-16     -1.0 -0.201299  0.97953 -0.965926   \n",
       "3             NaN  1.224647e-16     -1.0 -0.201299  0.97953 -0.965926   \n",
       "4             NaN  1.224647e-16     -1.0 -0.201299  0.97953 -0.965926   \n",
       "\n",
       "     HR_cos    WK_sin   WK_cos  YR_2013  \n",
       "0 -0.258819 -0.781831  0.62349     True  \n",
       "1 -0.258819 -0.781831  0.62349     True  \n",
       "2 -0.258819 -0.781831  0.62349     True  \n",
       "3 -0.258819 -0.781831  0.62349     True  \n",
       "4 -0.258819 -0.781831  0.62349     True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataframes[\"train_call_type_A.csv\"]\n",
    "test_data  = dataframes[\"test_public.csv\"]\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>START_LOCATION</th>\n",
       "      <th>MON_sin</th>\n",
       "      <th>MON_cos</th>\n",
       "      <th>DAY_sin</th>\n",
       "      <th>DAY_cos</th>\n",
       "      <th>HR_sin</th>\n",
       "      <th>HR_cos</th>\n",
       "      <th>WK_sin</th>\n",
       "      <th>WK_cos</th>\n",
       "      <th>YR_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>A</td>\n",
       "      <td>42612.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T8</td>\n",
       "      <td>A</td>\n",
       "      <td>31780.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>T22</td>\n",
       "      <td>A</td>\n",
       "      <td>85698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>T23</td>\n",
       "      <td>A</td>\n",
       "      <td>37007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>T37</td>\n",
       "      <td>A</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID START_LOCATION   \n",
       "5       T6         A      42612.0           NaN  20000607            NaN  \\\n",
       "7       T8         A      31780.0           NaN  20000619            NaN   \n",
       "21     T22         A      85698.0           NaN  20000199            NaN   \n",
       "22     T23         A      37007.0           NaN  20000480            NaN   \n",
       "36     T37         A       2002.0           NaN  20000159            NaN   \n",
       "\n",
       "     MON_sin  MON_cos   DAY_sin   DAY_cos  HR_sin    HR_cos    WK_sin   \n",
       "5  -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025  0.433884  \\\n",
       "7  -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025  0.433884   \n",
       "21 -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025  0.433884   \n",
       "22 -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025  0.433884   \n",
       "36 -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025  0.433884   \n",
       "\n",
       "      WK_cos  YR_2013  \n",
       "5  -0.900969    False  \n",
       "7  -0.900969    False  \n",
       "21 -0.900969    False  \n",
       "22 -0.900969    False  \n",
       "36 -0.900969    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only data points with CALL_TYPE A\n",
    "test_data = test_data[test_data['CALL_TYPE'] == 'A']\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 346466 entries, 0 to 346465\n",
      "Data columns (total 21 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   TRIP_ID                          346466 non-null  int64  \n",
      " 1   CALL_TYPE                        346466 non-null  object \n",
      " 2   ORIGIN_CALL                      346466 non-null  float64\n",
      " 3   ORIGIN_STAND                     0 non-null       float64\n",
      " 4   TAXI_ID                          346466 non-null  int64  \n",
      " 5   POLYLINE                         346466 non-null  object \n",
      " 6   TRAVEL_TIME                      346466 non-null  int64  \n",
      " 7   START_LOCATION                   0 non-null       float64\n",
      " 8   MON_sin                          346466 non-null  float64\n",
      " 9   MON_cos                          346466 non-null  float64\n",
      " 10  DAY_sin                          346466 non-null  float64\n",
      " 11  DAY_cos                          346466 non-null  float64\n",
      " 12  HR_sin                           346466 non-null  float64\n",
      " 13  HR_cos                           346466 non-null  float64\n",
      " 14  WK_sin                           346466 non-null  float64\n",
      " 15  WK_cos                           346466 non-null  float64\n",
      " 16  YR_2013                          346466 non-null  bool   \n",
      " 17  TAXI_ID_MEAN_ENC                 346466 non-null  float64\n",
      " 18  ORIGIN_CALL_MEAN_ENC             346466 non-null  float64\n",
      " 19  TAXI_ID_MEAN_ENC_NORMALIZED      346466 non-null  float64\n",
      " 20  ORIGIN_CALL_MEAN_ENC_NORMALIZED  346466 non-null  float64\n",
      "dtypes: bool(1), float64(15), int64(3), object(2)\n",
      "memory usage: 53.2+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tyler Holston\\AppData\\Local\\Temp\\ipykernel_27540\\1169247368.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'TAXI_ID_MEAN_ENC'] = test_data['TAXI_ID'].map(mean_encoding_taxi_dict)\n",
      "C:\\Users\\Tyler Holston\\AppData\\Local\\Temp\\ipykernel_27540\\1169247368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC'] = test_data['ORIGIN_CALL'].map(mean_encoding_call_dict)\n",
      "C:\\Users\\Tyler Holston\\AppData\\Local\\Temp\\ipykernel_27540\\1169247368.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['ORIGIN_CALL_MEAN_ENC'].fillna(overall_mean_enc, inplace=True)\n",
      "C:\\Users\\Tyler Holston\\AppData\\Local\\Temp\\ipykernel_27540\\1169247368.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'TAXI_ID_MEAN_ENC_NORMALIZED'] = normalized_taxi_enc_test\n",
      "C:\\Users\\Tyler Holston\\AppData\\Local\\Temp\\ipykernel_27540\\1169247368.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC_NORMALIZED'] = normalized_call_enc_test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "mean_encoding_taxi = train_data.groupby('TAXI_ID')['TRAVEL_TIME'].mean().reset_index()\n",
    "mean_encoding_call = train_data.groupby('ORIGIN_CALL')['TRAVEL_TIME'].mean().reset_index()\n",
    "\n",
    "# Create a dictionary mapping 'TAXI_ID' to mean 'TRAVEL_TIME' value\n",
    "mean_encoding_taxi_dict = dict(zip(mean_encoding_taxi['TAXI_ID'], mean_encoding_taxi['TRAVEL_TIME']))\n",
    "\n",
    "# Create a dictionary mapping 'ORIGIN_CALL' to mean 'TRAVEL_TIME' value\n",
    "mean_encoding_call_dict = dict(zip(mean_encoding_call['ORIGIN_CALL'], mean_encoding_call['TRAVEL_TIME']))\n",
    "\n",
    "# Replace the 'TAXI_ID' values with mean target encoding values\n",
    "train_data.loc[:, 'TAXI_ID_MEAN_ENC'] = train_data['TAXI_ID'].map(mean_encoding_taxi_dict)\n",
    "test_data.loc[:, 'TAXI_ID_MEAN_ENC'] = test_data['TAXI_ID'].map(mean_encoding_taxi_dict)\n",
    "\n",
    "# Replace the 'ORIGIN_CALL' values with mean target encoding values\n",
    "train_data.loc[:, 'ORIGIN_CALL_MEAN_ENC'] = train_data['ORIGIN_CALL'].map(mean_encoding_call_dict)\n",
    "test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC'] = test_data['ORIGIN_CALL'].map(mean_encoding_call_dict)\n",
    "\n",
    "overall_mean_enc = train_data['ORIGIN_CALL_MEAN_ENC'].mean()\n",
    "test_data['ORIGIN_CALL_MEAN_ENC'].fillna(overall_mean_enc, inplace=True)\n",
    "\n",
    "mean_taxi_enc_train = pd.DataFrame(train_data['TAXI_ID_MEAN_ENC'])\n",
    "mean_taxi_enc_test = pd.DataFrame(test_data['TAXI_ID_MEAN_ENC'])\n",
    "mean_call_enc_train = pd.DataFrame(train_data['ORIGIN_CALL_MEAN_ENC'])\n",
    "mean_call_enc_test = pd.DataFrame(test_data['ORIGIN_CALL_MEAN_ENC'])\n",
    "\n",
    "# Initialize StandardScaler and fit it on the mean encoding column\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(mean_taxi_enc_train)\n",
    "\n",
    "# Transform the mean encoding column using the fitted scaler\n",
    "normalized_taxi_enc_train = scaler.transform(mean_taxi_enc_train)\n",
    "normalized_taxi_enc_test = scaler.transform(mean_taxi_enc_test)\n",
    "\n",
    "# Replace the original mean encoding column with the normalized values\n",
    "train_data.loc[:, 'TAXI_ID_MEAN_ENC_NORMALIZED'] = normalized_taxi_enc_train\n",
    "test_data.loc[:, 'TAXI_ID_MEAN_ENC_NORMALIZED'] = normalized_taxi_enc_test\n",
    "\n",
    "# Initialize StandardScaler and fit it on the mean encoding column\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(mean_call_enc_train)\n",
    "\n",
    "# Transform the mean encoding column using the fitted scaler\n",
    "normalized_call_enc_train = scaler.transform(mean_call_enc_train)\n",
    "normalized_call_enc_test = scaler.transform(mean_call_enc_test)\n",
    "\n",
    "# Replace the original mean encoding column with the normalized values\n",
    "train_data.loc[:, 'ORIGIN_CALL_MEAN_ENC_NORMALIZED'] = normalized_call_enc_train\n",
    "test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC_NORMALIZED'] = normalized_call_enc_test\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We could totally change this. Utilization of these just probably requires further preprocessing.\n",
    "ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION = ['TRIP_ID', 'CALL_TYPE', 'ORIGIN_STAND', 'POLYLINE', 'START_LOCATION', 'ORIGIN_CALL', 'TAXI_ID', 'ORIGIN_CALL_MEAN_ENC', 'TAXI_ID_MEAN_ENC']\n",
    "\n",
    "train_data_sample = train_data.sample(frac=0.8, random_state=420) # frac is used to control percentage of train data used\n",
    "X = train_data_sample.drop(\"TRAVEL_TIME\", axis=1)\n",
    "X = X.loc[:, ~X.columns.isin(ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION)]\n",
    "y = train_data_sample[\"TRAVEL_TIME\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=420)\n",
    "\n",
    "test_features = test_data.loc[:, ~test_data.columns.isin(ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from mlp_utils import TaxiDataset\n",
    "    \n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "X_test_public = test_features.astype(float) # This is what we can predict on\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.tolist(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.tolist(), dtype=torch.float32)\n",
    "X_test_public_tensor = torch.tensor(X_test_public.values, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TaxiDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TaxiDataset(X_test_tensor, y_test_tensor)\n",
    "test_public_dataset = TaxiDataset(X_test_public_tensor)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_pred = DataLoader(test_public_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def init_weights(m):\n",
    "  if isinstance(m, nn.Linear):\n",
    "    nn.init.xavier_uniform_(m.weight)\n",
    "    m.bias.data.fill_(0.01)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron for regression.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(11, 256)\n",
    "    self.fc2 = nn.Linear(256, 256)\n",
    "    self.fc3 = nn.Linear(256, 256)\n",
    "    self.fc4 = nn.Linear(256, 128)\n",
    "    self.fc5 = nn.Linear(128, 64)\n",
    "    self.fc6 = nn.Linear(64, 1)\n",
    "    self.apply(init_weights)\n",
    "    self.apply(init_weights)\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''\n",
    "      Forward pass\n",
    "    '''\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = F.relu(self.fc3(x))\n",
    "    x = F.relu(self.fc4(x))\n",
    "    x = F.relu(self.fc5(x))\n",
    "    x = self.fc6(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175873"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlp_utils import num_parameters\n",
    "\n",
    "mlp = MLP()\n",
    "if torch.cuda.is_available():\n",
    "    mlp.cuda()\n",
    " \n",
    "num_parameters(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:07<00:00, 18.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "from mlp_utils import pipeline\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=0.001, weight_decay=1e-2)\n",
    "\n",
    "train_losses, test_loss, predictions = pipeline(mlp, optimizer, dataloader_train=dataloader_train, \n",
    "                                                dataloader_test=dataloader_test, dataloader_pred=dataloader_pred,\n",
    "                        \t\t\tdevice=device, criterion=criterion, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Loss: 315.3367693648248\n",
      "Test Loss: 316.5821367018478\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Train Loss: {train_losses[-1]}\")\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp_utils import test_prediction_to_csv\n",
    "\n",
    "test_prediction_to_csv(predictions, \"predicting_six_layer_mlp_call_type_a.csv\", test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
