{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE: train_call_type_A.csv\n",
      "FILE: train_call_type_B.csv\n",
      "FILE: train_call_type_C.csv\n",
      "FILE: test_public.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import math\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "\n",
    "zipped_data_path = \"../data/clean_data/class-competition-cleaned.zip\"\n",
    "\n",
    "dataframes = defaultdict(pd.DataFrame)\n",
    "with zipfile.ZipFile(zipped_data_path, \"r\") as zipf:\n",
    "    for filename in zipf.namelist():\n",
    "        if filename.endswith(\".csv\"):\n",
    "            with zipf.open(filename) as f:\n",
    "                dataframes.update({ filename : pd.read_csv(io.TextIOWrapper(f)) })\n",
    "\n",
    "                # Lets take a look at the files\n",
    "                print(f\"FILE: {filename}\")\n",
    "                # If you want to see file info uncomment this:\n",
    "                # display(dataframes[filename].info())\n",
    "                # display(dataframes[filename].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "      <th>START_LOCATION</th>\n",
       "      <th>MON_sin</th>\n",
       "      <th>MON_cos</th>\n",
       "      <th>DAY_sin</th>\n",
       "      <th>DAY_cos</th>\n",
       "      <th>HR_sin</th>\n",
       "      <th>HR_cos</th>\n",
       "      <th>MIN_sin</th>\n",
       "      <th>MIN_cos</th>\n",
       "      <th>WK_sin</th>\n",
       "      <th>WK_cos</th>\n",
       "      <th>YR_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372637343620000571</td>\n",
       "      <td>A</td>\n",
       "      <td>31508.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000571</td>\n",
       "      <td>[[-8.618868,41.155101],[-8.6175,41.154912],[-8...</td>\n",
       "      <td>465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>5.877853e-01</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372639135620000570</td>\n",
       "      <td>A</td>\n",
       "      <td>33180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000570</td>\n",
       "      <td>[[-8.666757,41.174055],[-8.666784,41.174064],[...</td>\n",
       "      <td>270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.743145</td>\n",
       "      <td>-6.691306e-01</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372637254620000657</td>\n",
       "      <td>A</td>\n",
       "      <td>39233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000657</td>\n",
       "      <td>[[-8.660646,41.168574],[-8.661087,41.167926],[...</td>\n",
       "      <td>630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>7.431448e-01</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372637658620000596</td>\n",
       "      <td>A</td>\n",
       "      <td>22864.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000596</td>\n",
       "      <td>[[-8.665686,41.170626],[-8.665677,41.170653],[...</td>\n",
       "      <td>375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.994522</td>\n",
       "      <td>1.045285e-01</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372639535620000161</td>\n",
       "      <td>A</td>\n",
       "      <td>25862.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000161</td>\n",
       "      <td>[[-8.648226,41.148333],[-8.648514,41.148297],[...</td>\n",
       "      <td>840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   \n",
       "0  1372637343620000571         A      31508.0           NaN  20000571  \\\n",
       "1  1372639135620000570         A      33180.0           NaN  20000570   \n",
       "2  1372637254620000657         A      39233.0           NaN  20000657   \n",
       "3  1372637658620000596         A      22864.0           NaN  20000596   \n",
       "4  1372639535620000161         A      25862.0           NaN  20000161   \n",
       "\n",
       "                                            POLYLINE  TRAVEL_TIME   \n",
       "0  [[-8.618868,41.155101],[-8.6175,41.154912],[-8...          465  \\\n",
       "1  [[-8.666757,41.174055],[-8.666784,41.174064],[...          270   \n",
       "2  [[-8.660646,41.168574],[-8.661087,41.167926],[...          630   \n",
       "3  [[-8.665686,41.170626],[-8.665677,41.170653],[...          375   \n",
       "4  [[-8.648226,41.148333],[-8.648514,41.148297],[...          840   \n",
       "\n",
       "   START_LOCATION       MON_sin  MON_cos   DAY_sin  DAY_cos    HR_sin   \n",
       "0             NaN  1.224647e-16     -1.0 -0.201299  0.97953 -0.965926  \\\n",
       "1             NaN  1.224647e-16     -1.0 -0.201299  0.97953 -0.965926   \n",
       "2             NaN  1.224647e-16     -1.0 -0.201299  0.97953 -0.965926   \n",
       "3             NaN  1.224647e-16     -1.0 -0.201299  0.97953 -0.965926   \n",
       "4             NaN  1.224647e-16     -1.0 -0.201299  0.97953 -0.965926   \n",
       "\n",
       "     HR_cos   MIN_sin       MIN_cos    WK_sin   WK_cos  YR_2013  \n",
       "0 -0.258819  0.809017  5.877853e-01 -0.781831  0.62349     True  \n",
       "1 -0.258819 -0.743145 -6.691306e-01 -0.781831  0.62349     True  \n",
       "2 -0.258819  0.669131  7.431448e-01 -0.781831  0.62349     True  \n",
       "3 -0.258819  0.994522  1.045285e-01 -0.781831  0.62349     True  \n",
       "4 -0.258819 -1.000000 -1.836970e-16 -0.781831  0.62349     True  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataframes[\"train_call_type_A.csv\"]\n",
    "test_data  = dataframes[\"test_public.csv\"]\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>START_LOCATION</th>\n",
       "      <th>MON_sin</th>\n",
       "      <th>MON_cos</th>\n",
       "      <th>DAY_sin</th>\n",
       "      <th>DAY_cos</th>\n",
       "      <th>HR_sin</th>\n",
       "      <th>HR_cos</th>\n",
       "      <th>MIN_sin</th>\n",
       "      <th>MIN_cos</th>\n",
       "      <th>WK_sin</th>\n",
       "      <th>WK_cos</th>\n",
       "      <th>YR_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>A</td>\n",
       "      <td>42612.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T8</td>\n",
       "      <td>A</td>\n",
       "      <td>31780.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>T22</td>\n",
       "      <td>A</td>\n",
       "      <td>85698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>T23</td>\n",
       "      <td>A</td>\n",
       "      <td>37007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>T37</td>\n",
       "      <td>A</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.913545</td>\n",
       "      <td>-0.406737</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID START_LOCATION   \n",
       "5       T6         A      42612.0           NaN  20000607            NaN  \\\n",
       "7       T8         A      31780.0           NaN  20000619            NaN   \n",
       "21     T22         A      85698.0           NaN  20000199            NaN   \n",
       "22     T23         A      37007.0           NaN  20000480            NaN   \n",
       "36     T37         A       2002.0           NaN  20000159            NaN   \n",
       "\n",
       "     MON_sin  MON_cos   DAY_sin   DAY_cos  HR_sin    HR_cos   MIN_sin   \n",
       "5  -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025  0.500000  \\\n",
       "7  -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025 -0.500000   \n",
       "21 -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025 -0.406737   \n",
       "22 -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025 -0.500000   \n",
       "36 -0.866025     -0.5  0.299363 -0.954139     0.5 -0.866025 -0.913545   \n",
       "\n",
       "     MIN_cos    WK_sin    WK_cos  YR_2013  \n",
       "5  -0.866025  0.433884 -0.900969    False  \n",
       "7   0.866025  0.433884 -0.900969    False  \n",
       "21  0.913545  0.433884 -0.900969    False  \n",
       "22  0.866025  0.433884 -0.900969    False  \n",
       "36 -0.406737  0.433884 -0.900969    False  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only data points with CALL_TYPE A\n",
    "test_data = test_data[test_data['CALL_TYPE'] == 'A']\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 346466 entries, 0 to 346465\n",
      "Data columns (total 23 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   TRIP_ID                          346466 non-null  int64  \n",
      " 1   CALL_TYPE                        346466 non-null  object \n",
      " 2   ORIGIN_CALL                      346466 non-null  float64\n",
      " 3   ORIGIN_STAND                     0 non-null       float64\n",
      " 4   TAXI_ID                          346466 non-null  int64  \n",
      " 5   POLYLINE                         346466 non-null  object \n",
      " 6   TRAVEL_TIME                      346466 non-null  int64  \n",
      " 7   START_LOCATION                   0 non-null       float64\n",
      " 8   MON_sin                          346466 non-null  float64\n",
      " 9   MON_cos                          346466 non-null  float64\n",
      " 10  DAY_sin                          346466 non-null  float64\n",
      " 11  DAY_cos                          346466 non-null  float64\n",
      " 12  HR_sin                           346466 non-null  float64\n",
      " 13  HR_cos                           346466 non-null  float64\n",
      " 14  MIN_sin                          346466 non-null  float64\n",
      " 15  MIN_cos                          346466 non-null  float64\n",
      " 16  WK_sin                           346466 non-null  float64\n",
      " 17  WK_cos                           346466 non-null  float64\n",
      " 18  YR_2013                          346466 non-null  bool   \n",
      " 19  TAXI_ID_MEAN_ENC                 346466 non-null  float64\n",
      " 20  ORIGIN_CALL_MEAN_ENC             346466 non-null  float64\n",
      " 21  TAXI_ID_MEAN_ENC_NORMALIZED      346466 non-null  float64\n",
      " 22  ORIGIN_CALL_MEAN_ENC_NORMALIZED  346466 non-null  float64\n",
      "dtypes: bool(1), float64(17), int64(3), object(2)\n",
      "memory usage: 58.5+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tyler Holston\\AppData\\Local\\Temp\\ipykernel_41236\\1169247368.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'TAXI_ID_MEAN_ENC'] = test_data['TAXI_ID'].map(mean_encoding_taxi_dict)\n",
      "C:\\Users\\Tyler Holston\\AppData\\Local\\Temp\\ipykernel_41236\\1169247368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC'] = test_data['ORIGIN_CALL'].map(mean_encoding_call_dict)\n",
      "C:\\Users\\Tyler Holston\\AppData\\Local\\Temp\\ipykernel_41236\\1169247368.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['ORIGIN_CALL_MEAN_ENC'].fillna(overall_mean_enc, inplace=True)\n",
      "C:\\Users\\Tyler Holston\\AppData\\Local\\Temp\\ipykernel_41236\\1169247368.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'TAXI_ID_MEAN_ENC_NORMALIZED'] = normalized_taxi_enc_test\n",
      "C:\\Users\\Tyler Holston\\AppData\\Local\\Temp\\ipykernel_41236\\1169247368.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC_NORMALIZED'] = normalized_call_enc_test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "mean_encoding_taxi = train_data.groupby('TAXI_ID')['TRAVEL_TIME'].mean().reset_index()\n",
    "mean_encoding_call = train_data.groupby('ORIGIN_CALL')['TRAVEL_TIME'].mean().reset_index()\n",
    "\n",
    "# Create a dictionary mapping 'TAXI_ID' to mean 'TRAVEL_TIME' value\n",
    "mean_encoding_taxi_dict = dict(zip(mean_encoding_taxi['TAXI_ID'], mean_encoding_taxi['TRAVEL_TIME']))\n",
    "\n",
    "# Create a dictionary mapping 'ORIGIN_CALL' to mean 'TRAVEL_TIME' value\n",
    "mean_encoding_call_dict = dict(zip(mean_encoding_call['ORIGIN_CALL'], mean_encoding_call['TRAVEL_TIME']))\n",
    "\n",
    "# Replace the 'TAXI_ID' values with mean target encoding values\n",
    "train_data.loc[:, 'TAXI_ID_MEAN_ENC'] = train_data['TAXI_ID'].map(mean_encoding_taxi_dict)\n",
    "test_data.loc[:, 'TAXI_ID_MEAN_ENC'] = test_data['TAXI_ID'].map(mean_encoding_taxi_dict)\n",
    "\n",
    "# Replace the 'ORIGIN_CALL' values with mean target encoding values\n",
    "train_data.loc[:, 'ORIGIN_CALL_MEAN_ENC'] = train_data['ORIGIN_CALL'].map(mean_encoding_call_dict)\n",
    "test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC'] = test_data['ORIGIN_CALL'].map(mean_encoding_call_dict)\n",
    "\n",
    "overall_mean_enc = train_data['ORIGIN_CALL_MEAN_ENC'].mean()\n",
    "test_data['ORIGIN_CALL_MEAN_ENC'].fillna(overall_mean_enc, inplace=True)\n",
    "\n",
    "mean_taxi_enc_train = pd.DataFrame(train_data['TAXI_ID_MEAN_ENC'])\n",
    "mean_taxi_enc_test = pd.DataFrame(test_data['TAXI_ID_MEAN_ENC'])\n",
    "mean_call_enc_train = pd.DataFrame(train_data['ORIGIN_CALL_MEAN_ENC'])\n",
    "mean_call_enc_test = pd.DataFrame(test_data['ORIGIN_CALL_MEAN_ENC'])\n",
    "\n",
    "# Initialize StandardScaler and fit it on the mean encoding column\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(mean_taxi_enc_train)\n",
    "\n",
    "# Transform the mean encoding column using the fitted scaler\n",
    "normalized_taxi_enc_train = scaler.transform(mean_taxi_enc_train)\n",
    "normalized_taxi_enc_test = scaler.transform(mean_taxi_enc_test)\n",
    "\n",
    "# Replace the original mean encoding column with the normalized values\n",
    "train_data.loc[:, 'TAXI_ID_MEAN_ENC_NORMALIZED'] = normalized_taxi_enc_train\n",
    "test_data.loc[:, 'TAXI_ID_MEAN_ENC_NORMALIZED'] = normalized_taxi_enc_test\n",
    "\n",
    "# Initialize StandardScaler and fit it on the mean encoding column\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(mean_call_enc_train)\n",
    "\n",
    "# Transform the mean encoding column using the fitted scaler\n",
    "normalized_call_enc_train = scaler.transform(mean_call_enc_train)\n",
    "normalized_call_enc_test = scaler.transform(mean_call_enc_test)\n",
    "\n",
    "# Replace the original mean encoding column with the normalized values\n",
    "train_data.loc[:, 'ORIGIN_CALL_MEAN_ENC_NORMALIZED'] = normalized_call_enc_train\n",
    "test_data.loc[:, 'ORIGIN_CALL_MEAN_ENC_NORMALIZED'] = normalized_call_enc_test\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We could totally change this. Utilization of these just probably requires further preprocessing.\n",
    "ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION = ['TRIP_ID', 'POLYLINE', 'START_LOCATION', 'TAXI_ID', 'ORIGIN_CALL_MEAN_ENC', 'TAXI_ID_MEAN_ENC']\n",
    "\n",
    "train_data_sample = train_data.sample(frac=0.8, random_state=420) # frac is used to control percentage of train data used\n",
    "X = train_data_sample.drop(\"TRAVEL_TIME\", axis=1)\n",
    "X = X.loc[:, ~X.columns.isin(ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION)]\n",
    "y = train_data_sample[\"TRAVEL_TIME\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=420)\n",
    "\n",
    "test_features = test_data.loc[:, ~test_data.columns.isin(ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from mlp_utils import TaxiDataset\n",
    "    \n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "X_test_public = test_features.astype(float) # This is what we can predict on\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.tolist(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.tolist(), dtype=torch.float32)\n",
    "X_test_public_tensor = torch.tensor(X_test_public.values, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TaxiDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TaxiDataset(X_test_tensor, y_test_tensor)\n",
    "test_public_dataset = TaxiDataset(X_test_public_tensor)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_pred = DataLoader(test_public_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_unique_taxi_id = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def init_weights(m):\n",
    "  if isinstance(m, nn.Linear):\n",
    "    nn.init.xavier_uniform_(m.weight)\n",
    "    m.bias.data.fill_(0.01)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron for regression.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.taxi_id_embedding = nn.Embedding(, 10)\n",
    "    self.origin_call_embedding = nn.Embedding(, 10)\n",
    "    self.origin_stand_embedding = nn.Embedding(, 10)\n",
    "    self.fc1 = nn.Linear(13, 128)\n",
    "    self.dropout1 = nn.Dropout(0.5)\n",
    "    self.fc2 = nn.Linear(128, 128)\n",
    "    self.dropout2 = nn.Dropout(0.5)\n",
    "    self.fc3 = nn.Linear(128, 128)\n",
    "    self.dropout3 = nn.Dropout(0.5)\n",
    "    self.fc4 = nn.Linear(128, 64)\n",
    "    self.dropout4 = nn.Dropout(0.5)\n",
    "    self.fc5 = nn.Linear(64, 32)\n",
    "    self.dropout5 = nn.Dropout(0.3)\n",
    "    self.fc6 = nn.Linear(32, 1)\n",
    "    self.apply(init_weights)\n",
    "    self.apply(init_weights)\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''\n",
    "      Forward pass\n",
    "    '''\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.dropout1(x)\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.dropout2(x)\n",
    "    x = F.relu(self.fc3(x))\n",
    "    x = self.dropout3(x)\n",
    "    x = F.relu(self.fc4(x))\n",
    "    x = self.dropout4(x)\n",
    "    x = F.relu(self.fc5(x))\n",
    "    x = self.fc6(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45185"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlp_utils import num_parameters\n",
    "\n",
    "mlp = MLP()\n",
    "if torch.cuda.is_available():\n",
    "    mlp.cuda()\n",
    " \n",
    "num_parameters(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:18<1:01:05, 18.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss = 398.40565464792076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:36<1:00:03, 18.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train Loss = 357.8407000452719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:54<59:40, 18.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train Loss = 353.6791174817124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [01:12<59:36, 18.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Train Loss = 350.0653142879307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [01:31<59:11, 18.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss = 348.67600623472214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [01:49<58:42, 18.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train Loss = 347.2524507400972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [02:07<58:22, 18.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Train Loss = 346.01076419429927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [02:25<58:02, 18.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Train Loss = 345.21370937576404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [02:43<57:32, 18.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Train Loss = 344.12834886301385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [03:01<57:42, 18.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss = 343.0157160904605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [03:20<57:18, 18.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Train Loss = 341.66415355410214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [03:37<56:46, 18.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Train Loss = 341.4071956273371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [03:55<56:12, 18.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Train Loss = 340.6015634271498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [04:13<55:51, 18.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Train Loss = 339.778681299165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [04:31<55:22, 17.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Train Loss = 338.2516358055405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [04:49<54:57, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Train Loss = 337.19729271219967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [05:07<54:37, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Train Loss = 336.7154182103654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [05:25<54:22, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Train Loss = 335.1949803675337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [05:43<54:03, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Train Loss = 334.8936112738755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [06:01<53:40, 17.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Train Loss = 334.0920268127951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [06:18<53:22, 17.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Train Loss = 333.556536710956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [06:36<53:06, 17.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Train Loss = 333.40682605297525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [06:54<52:44, 17.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Train Loss = 332.629435309096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [07:12<52:31, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Train Loss = 331.98247521135653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [07:30<52:23, 17.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Train Loss = 331.8585270163526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [07:48<51:55, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Train Loss = 331.07061924979513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [08:06<51:35, 17.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Train Loss = 331.28969813588446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [08:24<51:19, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 - Train Loss = 331.05598669738833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [08:42<51:03, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 - Train Loss = 330.5370758478459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [09:00<50:46, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Train Loss = 330.5803702207882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [09:18<50:32, 17.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 - Train Loss = 329.9106507470254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [09:36<50:11, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 - Train Loss = 330.1274779237674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/200 [09:53<49:52, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 - Train Loss = 330.19188049725847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [10:11<49:34, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 - Train Loss = 329.53249941519664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 35/200 [10:29<49:14, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 - Train Loss = 329.53851028445155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/200 [10:47<48:53, 17.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 - Train Loss = 329.2848419877045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/200 [11:06<49:12, 18.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 - Train Loss = 329.2253996718948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38/200 [11:24<48:57, 18.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 - Train Loss = 329.3408573514854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39/200 [11:42<48:35, 18.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 - Train Loss = 329.16662801129286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [12:00<48:01, 18.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 - Train Loss = 329.1749323407211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [12:16<49:06, 18.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m      5\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(mlp\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m, weight_decay\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m train_losses, test_loss, predictions \u001b[39m=\u001b[39m pipeline(mlp, optimizer, dataloader_train\u001b[39m=\u001b[39;49mdataloader_train, \n\u001b[0;32m      8\u001b[0m                                                 dataloader_test\u001b[39m=\u001b[39;49mdataloader_test, dataloader_pred\u001b[39m=\u001b[39;49mdataloader_pred,\n\u001b[0;32m      9\u001b[0m                         \t\t\tdevice\u001b[39m=\u001b[39;49mdevice, criterion\u001b[39m=\u001b[39;49mcriterion, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Tyler Holston\\OneDrive\\Desktop\\AssortedPythonStuff\\perceptron-posse-kaggle\\mlp\\mlp_utils.py:89\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(network, optimizer, dataloader_train, dataloader_test, dataloader_pred, device, criterion, epochs, verbose)\u001b[0m\n\u001b[0;32m     86\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     88\u001b[0m \u001b[39m# Perform forward pass\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m outputs \u001b[39m=\u001b[39m network(inputs)\n\u001b[0;32m     91\u001b[0m \u001b[39m# Reshape labels for warning\u001b[39;00m\n\u001b[0;32m     92\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Tyler Holston\\OneDrive\\Desktop\\AssortedPythonStuff\\perceptron-posse-kaggle\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[42], line 34\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n\u001b[0;32m     33\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n\u001b[1;32m---> 34\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc2(x))\n\u001b[0;32m     35\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(x)\n\u001b[0;32m     36\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x))\n",
      "File \u001b[1;32mc:\\Users\\Tyler Holston\\OneDrive\\Desktop\\AssortedPythonStuff\\perceptron-posse-kaggle\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Tyler Holston\\OneDrive\\Desktop\\AssortedPythonStuff\\perceptron-posse-kaggle\\.venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mlp_utils import pipeline\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=0.0005, weight_decay=1e-3)\n",
    "\n",
    "train_losses, test_loss, predictions = pipeline(mlp, optimizer, dataloader_train=dataloader_train, \n",
    "                                                dataloader_test=dataloader_test, dataloader_pred=dataloader_pred,\n",
    "                        \t\t\tdevice=device, criterion=criterion, epochs=200, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Loss: 331.13196629970383\n",
      "Test Loss: 332.97012718445217\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Train Loss: {train_losses[-1]}\")\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[363.72629462779895, 338.0652894340494, 336.02922956629, 334.88988442822154, 333.77896367343027, 333.7846242961978, 332.2002389034503, 331.99065959855704, 331.1106559578354, 331.13196629970383]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create x-axis values (epochs)\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(epochs, train_losses, 'b-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp_utils import test_prediction_to_csv\n",
    "\n",
    "test_prediction_to_csv(predictions, \"predicting_six_layer_mlp_call_type_a_min.csv\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
