{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE: train.csv\n",
      "FILE: test_public.csv\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import math\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "\n",
    "zipped_data_path = \"../data/clean_data/class-competition.zip\"\n",
    "\n",
    "dataframes = defaultdict(pd.DataFrame)\n",
    "with zipfile.ZipFile(zipped_data_path, \"r\") as zip:\n",
    "    for filename in zip.namelist():\n",
    "        if filename.endswith(\".csv\"):\n",
    "            with zip.open(filename) as f:\n",
    "                dataframes.update({ filename : pd.read_csv(io.TextIOWrapper(f)) })\n",
    "\n",
    "                # Lets take a look at the files\n",
    "                print(f\"FILE: {filename}\")\n",
    "                # If you want to see file info uncomment this:\n",
    "                # display(dataframes[filename].info())\n",
    "                # display(dataframes[filename].head())\n",
    "\n",
    "train_data = dataframes[\"train.csv\"]\n",
    "test_data  = dataframes[\"test_public.csv\"]\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ALL_FEATURES = ['TRIP_ID', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID', 'MISSING_DATA',\n",
    " 'POLYLINE', 'CALL_TYPE_A', 'CALL_TYPE_B', 'CALL_TYPE_C', 'YEAR_2013', 'YEAR_2014',\n",
    " 'MONTH_1', 'MONTH_2', 'MONTH_3', 'MONTH_4', 'MONTH_5', 'MONTH_6',\n",
    " 'MONTH_7', 'MONTH_8', 'MONTH_9', 'MONTH_10', 'MONTH_11', 'MONTH_12',\n",
    " 'DAY_OF_WEEK_0', 'DAY_OF_WEEK_1', 'DAY_OF_WEEK_2', 'DAY_OF_WEEK_3',\n",
    " 'DAY_OF_WEEK_4', 'DAY_OF_WEEK_5', 'DAY_OF_WEEK_6', 'HOUR_0', 'HOUR_1',\n",
    " 'HOUR_2', 'HOUR_3', 'HOUR_4', 'HOUR_5', 'HOUR_6', 'HOUR_7', 'HOUR_8',\n",
    " 'HOUR_9', 'HOUR_10', 'HOUR_11', 'HOUR_12', 'HOUR_13', 'HOUR_14',\n",
    " 'HOUR_15', 'HOUR_16', 'HOUR_17', 'HOUR_18', 'HOUR_19', 'HOUR_20',\n",
    " 'HOUR_21', 'HOUR_22', 'HOUR_23']\n",
    "\n",
    "# We could totally change this. Utilization of these just probably requires further preprocessing.\n",
    "ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION = ['TRIP_ID', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID', 'POLYLINE']\n",
    "\n",
    "train_data_sample = train_data.sample(frac=0.2, random_state=420) # frac is used to control percentage of train data used\n",
    "X = train_data_sample.drop(\"TRAVEL_TIME\", axis=1)\n",
    "X = X.loc[:, ~X.columns.isin(ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION)]\n",
    "y = train_data_sample[\"TRAVEL_TIME\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=420)\n",
    "\n",
    "test_features = test_data.loc[:, ~test_data.columns.isin(ALL_FEATURES_NOT_SUITED_FOR_ESTIMATION)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from mlp_utils import TaxiDataset\n",
    "    \n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "X_test_public = test_features.astype(float) # This is what we can predict on\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.tolist(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.tolist(), dtype=torch.float32)\n",
    "X_test_public_tensor = torch.tensor(X_test_public.values, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TaxiDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TaxiDataset(X_test_tensor, y_test_tensor)\n",
    "test_public_dataset = TaxiDataset(X_test_public_tensor)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_pred = DataLoader(test_public_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron for regression.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(49, 256),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Linear(256, 128),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Linear(128, 64),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Linear(64, 32),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Linear(32, 1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''\n",
    "      Forward pass\n",
    "    '''\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56065"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlp_utils import num_parameters\n",
    "\n",
    "mlp = MLP()\n",
    "if torch.cuda.is_available():\n",
    "    mlp.cuda()\n",
    " \n",
    "num_parameters(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:55<00:00, 17.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "from mlp_utils import pipeline\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.001, weight_decay=1e-2)\n",
    "\n",
    "train_losses, test_loss, predictions = pipeline(mlp, optimizer, dataloader_train=dataloader_train, \n",
    "                                                dataloader_test=dataloader_test, dataloader_pred=dataloader_pred,\n",
    "                        \t\t\tdevice=device, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Loss: 693.5519860486353\n",
      "Test Loss: 687.7321852816522\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Train Loss: {train_losses[-1]}\")\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp_utils import test_prediction_to_csv\n",
    "\n",
    "test_prediction_to_csv(predictions, \"predicting_five_layer_mlp_sigmoid_lr_1e-2.csv\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
